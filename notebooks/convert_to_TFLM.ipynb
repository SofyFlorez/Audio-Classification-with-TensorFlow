{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3612c310",
   "metadata": {},
   "source": [
    "# Convert the Keras model to a TensorFlow Lite model\n",
    "\n",
    "This Jupyter notebook shows the steps for converting a trained Keras model saved in HDF5 format (.h5) to a TensorFlow Lite model (.tflite) for optimized mobile and embedded devices deployment. The TensorFlow Lite format provides a more compact and faster model representation that can easily run on platforms with limited computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd6c69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94138fd4",
   "metadata": {},
   "source": [
    "### Loading Keras Model\n",
    "\n",
    "First, the previously trained Keras model is loaded from the best_model.h5 file. This contains the neural network architecture and trained weights that will be converted to TensorFlow Lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d1e1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved Keras model\n",
    "model = tf.keras.models.load_model('/models/best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84def900",
   "metadata": {},
   "source": [
    "### Converting to TensorFlow Lite\n",
    "\n",
    "Next, a TensorFlow Lite converter is created from the loaded Keras model. This converter handles optimizing and translating the model to the .tflite format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff250ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9dd5a",
   "metadata": {},
   "source": [
    "### Optimizing Model\n",
    "\n",
    "Optimizations are applied to the model via the converter to reduce model size while retaining accuracy. This is important for efficient deployment. Common optimization strategies include weight quantization, pruning, and using built-in TensorFlow Lite operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8cf1aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 16:09:01.380651: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-08 16:09:01.380666: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-08 16:09:01.380772: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/pg/k661lbqs4sl4jplc4nftcthr0000gn/T/tmpui6nc83h\n",
      "2024-02-08 16:09:01.381959: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-08 16:09:01.381963: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/pg/k661lbqs4sl4jplc4nftcthr0000gn/T/tmpui6nc83h\n",
      "2024-02-08 16:09:01.384879: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-08 16:09:01.459805: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/pg/k661lbqs4sl4jplc4nftcthr0000gn/T/tmpui6nc83h\n",
      "2024-02-08 16:09:01.469755: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 88982 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 13, Total Ops 28, % non-converted = 46.43 %\n",
      " * 13 ARITH ops\n",
      "\n",
      "- arith.constant:   13 occurrences  (f32: 12, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# Implement optimization strategy for smaller model sizes\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167b488",
   "metadata": {},
   "source": [
    "### Saving TensorFlow Lite Model\n",
    "\n",
    "Finally, the optimized TensorFlow Lite model is saved to a model.tflite file. This can now be loaded on mobile devices or microcontrollers for performing fast and efficient on-device ML inferencing.\n",
    "\n",
    "The resulting .tflite model is now ready to be integrated into mobile, IoT and embedded applications. The converter output shows model statistics like operation types and percentages to help gauge conversion success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3358a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TFLite model\n",
    "with open('/models/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "904c294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved!\n"
     ]
    }
   ],
   "source": [
    "print(\"TFLite model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
