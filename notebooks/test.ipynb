{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025d250c",
   "metadata": {},
   "source": [
    "# Test the accuracy of the TFLite model \n",
    "\n",
    "This project tests the accuracy of a TensorFlow Lite model for audio classification. The model classifies audio clips into two categories: dog barks and sirens. Mel spectrograms are extracted from audio clips and used as input to the model. The project loads a pretrained quantized TFLite model, runs inference on a test set, and calculates the accuracy compared to the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c1739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02849f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data paths and hyperparameters\n",
    "data_dir = 'data'\n",
    "classes = ['dog_bark', 'siren']\n",
    "target_shape = (128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b8e52",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n",
    "\n",
    "The `load_and_preprocess_data` function loads audio clips from disk, extracts mel spectrograms using librosa, resizes the spectrograms to the expected input shape, and collects the data and corresponding labels. The raw audio and sample rate are loaded, then a mel spectrogram feature representation is extracted. The spectrograms are resized to match what the model expects as input. The data and labels are gathered in arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaa3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load audio data from disk and preprocess into mel spectrograms\n",
    "def load_and_preprocess_data(data_dir, classes, target_shape):\n",
    "    # Initialize empty lists to hold data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # Loop through class names\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                # Load audio data and sample rate\n",
    "                file_path = os.path.join(class_dir, filename)\n",
    "                audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "                # Extract mel spectrogram\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "                mel_spectrogram = mel_spectrogram.squeeze()\n",
    "\n",
    "                # Resize spectrogram\n",
    "                mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
    "\n",
    "                # Append data and labels\n",
    "                data.append(mel_spectrogram)\n",
    "                labels.append(i)\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6127dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data, labels = load_and_preprocess_data(data_dir, classes, target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "befeb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "labels = to_categorical(labels, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a0a42",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "The preprocessed data and labels are split into train and test sets using scikit-learn's `train_test_split`. 20% of the data is held out for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc5ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0928712",
   "metadata": {},
   "source": [
    "### Load and Test TFLite Model\n",
    "\n",
    "A quantized TFLite model is loaded from disk and the tensors are allocated. The input and output tensor details are fetched. Batches of test data are passed to the interpreter and inference is performed. The predictions are compared to the ground truth labels to calculate the accuracy. Finally, the overall test accuracy is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de3331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model\n",
    "# interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter = tf.lite.Interpreter(model_path=\"quant_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c3c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4538c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4f0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def compute_accuracy(output, y):\n",
    "    preds = np.argmax(output, axis=1)\n",
    "    return np.sum(preds == np.argmax(y, axis=1)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f938bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9093264248704663\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "batch_size = 32\n",
    "num_samples = X_test.shape[0]\n",
    "test_accuracy = 0\n",
    "\n",
    "for i in range(0, num_samples, batch_size):\n",
    "    test_data = X_test[i:i + batch_size]\n",
    "\n",
    "    for j in range(len(test_data)):\n",
    "        current_sample = test_data[j]\n",
    "        current_sample = np.expand_dims(current_sample, axis=0)  # Add batch dimension\n",
    "        interpreter.set_tensor(input_details[0]['index'], current_sample)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        test_accuracy += compute_accuracy(output, y_test[i + j:i + j + 1])\n",
    "\n",
    "test_accuracy /= num_samples\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
